{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Baselines\n",
    "\n",
    "This notebook runs the OpenAI model baselines on the Only Connect dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johngiorgi/.pyenv/versions/3.8.13/envs/only-connect/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %pip install -r requirements.txt\n",
    "# %pip install guidance --upgrade\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from ocw.evaluate_only_connect import Evaluate\n",
    "from ocw.common import TEST_FN, TRAIN_FN, VALID_FN\n",
    "\n",
    "import guidance\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, you will need to add your OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../baselines\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, download a copy of the Only Connect dataset from [here](https://drive.google.com/drive/folders/1118w_ydBSBWUru5cPlyGY9TMrgd993f3?usp=sharing). We expect the three JSON files exist under `dataset_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(dataset_dir)\n",
    "train_path = dataset_dir / TRAIN_FN\n",
    "valid_path = dataset_dir / VALID_FN\n",
    "test_path = dataset_dir / TEST_FN\n",
    "print(f\"Found train set: {train_path.exists()}\")\n",
    "print(f\"Found validation set: {valid_path.exists()}\")\n",
    "print(f\"Found test set: {test_path.exists()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load the dataset using the [HuggingFace Datasets Library](https://huggingface.co/docs/datasets/index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": str(train_path),\n",
    "        \"validation\": str(valid_path),\n",
    "        \"test\": str(test_path),\n",
    "    },\n",
    "    field=\"dataset\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, load the helper function with will make the calls to the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_openai(\n",
    "    dataset,\n",
    "    task: str = \"task1\",\n",
    "    model: str = \"gpt-3.5-turbo\",\n",
    "    split: str = \"test\",\n",
    "    num_in_context_examples: int = 3,\n",
    "    dry_run: bool = False,\n",
    "    seed: int = 42,\n",
    "    **kwargs,\n",
    "):\n",
    "    guidance.llm = guidance.llms.OpenAI(model)\n",
    "\n",
    "    if task == \"task1\":\n",
    "        prompt = guidance(\n",
    "            \"\"\"{{#system~}}You are currently competing in Round 3: Connecting Wall on the quiz show Only Connect. Your task: given 16 \"clues\" (words or phrases), solve the wall by grouping the clues into four groups of four. You will be given the clues as a list. You are also given examples of solved walls, which include the connections. Provide your answer as a list of four groups of four clues; separate groups by newlines and clues by commas. Do not try to guess the connection; only use the clues given and don't make up your own.\n",
    "\n",
    "Be careful! Connecting Wall is deliberately difficult. The puzzles are designed to include red herrings and to suggest more connections than actually exist. Some clues appear to fit into more than one category. Still, there is only one perfect solution for each wall.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "Example solved wall(s):\n",
    "\n",
    "{{examples}}\n",
    "\n",
    "Clues: {{#each clues}} {{this}}{{#unless @last}},{{/unless}}{{/each}}\n",
    "\n",
    "Solved wall:\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}{{gen 'predicted_groups' temperature=0.0 max_tokens=144}}{{~/assistant}}\"\"\",\n",
    "            **kwargs,\n",
    "        )\n",
    "    elif task == \"task2\":\n",
    "        prompt = guidance(\n",
    "            \"\"\"{{#system~}}You are currently competing in Round 3: Connecting Wall on the quiz show Only Connect. Your task: given 4 groups of 4 \"clues\" (words or phrases), determine the connection for each group. You will be given the groups as four lists of four. You are also given examples of solved walls, which include the connections. Provide your answer by repeating the four groups and adding it after \"Connection:\"\n",
    "\n",
    "Note: Connections might be thematic, linguistic, factual, mathematical and rely on both arcane subject areas and popular culture.                    \n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "Example solved wall(s):\n",
    "\n",
    "{{examples}}\n",
    "\n",
    "Groups:\n",
    "{{#each groups}}{{this}}. Connection:{{#unless @last}}\\n{{/unless}}{{/each}}\n",
    "\n",
    "Solved wall:\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}{{gen 'predicted_connections' temperature=0.0 max_tokens=144}}{{~/assistant}}\"\"\",\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    # Set the RNG here so repeated calls to this function will return the same results every time\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Create the in-context examples\n",
    "    ic_examples = \"\"\n",
    "    random_examples = rng.sample(dataset[\"train\"][\"groups\"], k=num_in_context_examples)\n",
    "    for i, example in enumerate(random_examples):\n",
    "        ic_examples += f\"Example {i+1}\\n\"\n",
    "        for group in example.values():\n",
    "            ic_examples += (\n",
    "                \", \".join(group[\"gt_words\"]) + f\". Connection: {group['gt_connection']}\\n\"\n",
    "            )\n",
    "        ic_examples += \"\\n\"\n",
    "    ic_examples = ic_examples.strip()\n",
    "\n",
    "    # Run the model on each wall\n",
    "    iterator = (\n",
    "        tqdm(dataset[split], desc=f\"Running {model} on {split}\")\n",
    "        if kwargs.get(\"silent\")\n",
    "        else dataset[split]\n",
    "    )\n",
    "    for i, wall in enumerate(iterator):\n",
    "        # Clues have already been shuffled, so we can take them as is\n",
    "        wall_id, clues = (\n",
    "            wall[\"wall_id\"],\n",
    "            wall[\"words\"],\n",
    "        )\n",
    "        groups = [\", \".join(group[\"gt_words\"]) for group in wall[\"groups\"].values()]\n",
    "        # Try to parse the model response, but if it fails, just use a random guess\n",
    "        predicted_groups, predicted_connections = None, None\n",
    "        if task == \"task1\":\n",
    "            response = prompt(examples=ic_examples, clues=clues)\n",
    "            # Remove any instances of \"[gG]roup X:\" from the response\n",
    "            predicted_groups = re.sub(\n",
    "                r\"Group\\s*\\d+\\s*:?\", \"\", response[\"predicted_groups\"], flags=re.I\n",
    "            )\n",
    "            predicted_groups = [\n",
    "                line.strip() for line in predicted_groups.splitlines() if line.strip()\n",
    "            ]\n",
    "            # Sometimes the model returns more or less than 4 groups, truncate or pad with empty strings\n",
    "            predicted_groups = predicted_groups[:4]\n",
    "            predicted_groups += [\"\"] * (4 - len(predicted_groups))\n",
    "            # Sometimes the model returns more or less than 4 words per group, truncate or pad with empty strings\n",
    "            predicted_groups = [\n",
    "                [word.strip() for word in line.split(\",\")][:4] for line in predicted_groups\n",
    "            ]\n",
    "            predicted_groups = [group + ([\"\"] * (4 - len(group))) for group in predicted_groups]\n",
    "            # Sometimes, the model returns the connection as part of the group, so we need to remove it\n",
    "            predicted_groups = [\n",
    "                [re.sub(r\"\\. Connection:.*\", \"\", word, flags=re.I) for word in group]\n",
    "                for group in predicted_groups\n",
    "            ]\n",
    "        else:\n",
    "            response = prompt(examples=ic_examples, groups=groups)\n",
    "            predicted_connections = [\n",
    "                re.search(r\"Connection:\\s*(.*)\", connection)\n",
    "                for connection in response[\"predicted_connections\"].splitlines()\n",
    "            ]\n",
    "            predicted_connections = [\n",
    "                connection.group(1).strip() if connection else \"\"\n",
    "                for connection in predicted_connections\n",
    "            ]\n",
    "            # Sometimes the model returns more than 4 connections, so we take the first 4\n",
    "            predicted_connections = predicted_connections[:4]\n",
    "            # If the model returns fewer than 4 connections, we pad with empty strings\n",
    "            predicted_connections += [\"\"] * (4 - len(predicted_connections))\n",
    "\n",
    "        predictions.append(\n",
    "            {\n",
    "                \"wall_id\": wall_id,\n",
    "                \"predicted_groups\": predicted_groups,\n",
    "                \"predicted_connections\": predicted_connections,\n",
    "                \"gt_groups\": [group[\"gt_words\"] for group in dataset[split][i][\"groups\"].values()],\n",
    "                \"gt_connections\": dataset[split][i][\"gt_connections\"],\n",
    "            }\n",
    "        )\n",
    "        if dry_run:\n",
    "            print(\"--dry-run flag passed. Exiting after one example.\")\n",
    "            break\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Solving Walls\n",
    "\n",
    "To run task 1 (solving the wall), run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-1d90cea1-b40c-4727-ae02-dba7d9b10e10\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-1d90cea1-b40c-4727-ae02-dba7d9b10e10\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are currently competing in Round 3: Connecting Wall on the quiz show Only Connect. Your task: given 16 &quot;clues&quot; (words or phrases), solve the wall by grouping the clues into four groups of four. You will be given the clues as a list. You are also given examples of solved walls, which include the connections. Provide your answer as a list of four groups of four clues; separate groups by newlines and clues by commas. Do not try to guess the connection; only use the clues given and don&#x27;t make up your own.\n",
       "\n",
       "Be careful! Connecting Wall is deliberately difficult. The puzzles are designed to include red herrings and to suggest more connections than actually exist. Some clues appear to fit into more than one category. Still, there is only one perfect solution for each wall.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>Example solved wall(s):\n",
       "\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{examples}}'>Example 1\n",
       "Autumn, Melancholy, Grecian Urn, Psyche. Connection: Odes by Keats\n",
       "The Machine, The Magic Roundabout, Nightingale, Michelangelos David. Connection: Florence\n",
       "The Flumps, Waybuloo, Noggin the Nog, Engie Benjy. Connection: Childrens TV programmes\n",
       "Woolloomooloo, Bondi Beach, Paddington, The Rocks. Connection: Places in Sydney\n",
       "\n",
       "Example 2\n",
       "Agnew, Blofeld, Boycott, Johnston. Connection: Test Match Special regulars\n",
       "Knees, Bike, Last legs, Marks. Connection: On your ___\n",
       "Banshees, Tory, Brock, Galore. Connection: Words originating from Irish\n",
       "Angled, Uppers, Elating, Eighth. Connection: Last letter to front = new word\n",
       "\n",
       "Example 3\n",
       "Wedge, Pump, Mule, Brogue. Connection: Types of shoe\n",
       "Wellington, Sandwich, Plimsoll, Pavlova. Connection: Named after famous people\n",
       "Custard, Vienna, Snowball, Cookie. Connection: TV cats\n",
       "Clover, Napoleon, Major, Boxer. Connection: Animal Farm characters</span>\n",
       "\n",
       "Clues: <span style='opacity: 1.0; display: inline; background-color: rgba(165, 165, 165, 0.1);' title='{{#each clues}} {{this}}{{#unless @last}},{{/unless}}{{/each}}'> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Puzzle</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Manhattan</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>B</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Wrench</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Smith</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Nuts</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Brooks</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Blanc</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Suit</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Screwdriver</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Sidecar</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Margarita</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Hammer</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Business</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Gimlet</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'>,</span> <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Gibson</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}},{{/unless}}'></span></span>\n",
       "\n",
       "Solved wall:</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;predicted_groups&#x27; temperature=0.0 max_tokens=144}}'>Puzzle, Wrench, Screwdriver, Hammer\n",
       "Manhattan, Sidecar, Margarita, Gimlet\n",
       "B, Smith, Brooks, Blanc\n",
       "Business, Suit, Nuts, Gibson</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"1d90cea1-b40c-4727-ae02-dba7d9b10e10\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--dry-run flag passed. Exiting after one example.\n"
     ]
    }
   ],
   "source": [
    "# Remove dry-run when you are ready to run the full dataset\n",
    "predictions = run_openai(\n",
    "    dataset, task=\"task1\", split=\"validation\", num_in_context_examples=3, dry_run=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce our results from the paper, run the following\n",
    "\n",
    "> Note: this can take about ~2 hours per experiement. Results will be cached so re-running the same examples will not result in API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"gpt-3.5-turbo-0301\"\n",
    "model = \"gpt-4-0314\"\n",
    "model_dir = Path(output_dir) / model\n",
    "pred_dir = model_dir / \"predictions\" / \"task1\"\n",
    "results_dir = model_dir / \"results\" / \"task1\"\n",
    "\n",
    "# Create the output directories if they don't exist\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for num_in_context_examples in [0, 1, 3, 5, 10]:\n",
    "    # for num_in_context_examples in [3, 5, 10]:\n",
    "    predictions = run_openai(\n",
    "        dataset,\n",
    "        task=\"task1\",\n",
    "        model=model,\n",
    "        split=\"test\",\n",
    "        num_in_context_examples=num_in_context_examples,\n",
    "        silent=True,\n",
    "        stream=False,\n",
    "        caching=False,\n",
    "    )\n",
    "\n",
    "    output_fn = f\"{num_in_context_examples}_in_context_examples.json\"\n",
    "    pred_fp = pred_dir / output_fn\n",
    "    results_path = results_dir / output_fn\n",
    "    pred_fp.write_text(json.dumps(predictions, ensure_ascii=False, indent=2))\n",
    "    evaluator = Evaluate(\n",
    "        str(pred_fp), dataset_path=str(dataset_dir), results_path=str(results_path), split=\"test\"\n",
    "    )\n",
    "    evaluator.task1_grouping_evaluation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Making Connections\n",
    "\n",
    "To run task 2 (predicting the connections between solved groups), run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-9e2dbbcd-c9da-491d-bc01-4af2c312170a\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-9e2dbbcd-c9da-491d-bc01-4af2c312170a\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>You are currently competing in Round 3: Connecting Wall on the quiz show Only Connect. Your task: given 4 groups of 4 &quot;clues&quot; (words or phrases), determine the connection for each group. You will be given the groups as four lists of four. You are also given examples of solved walls, which include the connections. Provide your answer by repeating the four groups and adding it after &quot;Connection:&quot;\n",
       "\n",
       "Note: Connections might be thematic, linguistic, factual, mathematical and rely on both arcane subject areas and popular culture.</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>Example solved wall(s):\n",
       "\n",
       "<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{examples}}'>Example 1\n",
       "Autumn, Melancholy, Grecian Urn, Psyche. Connection: Odes by Keats\n",
       "The Machine, The Magic Roundabout, Nightingale, Michelangelos David. Connection: Florence\n",
       "The Flumps, Waybuloo, Noggin the Nog, Engie Benjy. Connection: Childrens TV programmes\n",
       "Woolloomooloo, Bondi Beach, Paddington, The Rocks. Connection: Places in Sydney\n",
       "\n",
       "Example 2\n",
       "Agnew, Blofeld, Boycott, Johnston. Connection: Test Match Special regulars\n",
       "Knees, Bike, Last legs, Marks. Connection: On your ___\n",
       "Banshees, Tory, Brock, Galore. Connection: Words originating from Irish\n",
       "Angled, Uppers, Elating, Eighth. Connection: Last letter to front = new word\n",
       "\n",
       "Example 3\n",
       "Wedge, Pump, Mule, Brogue. Connection: Types of shoe\n",
       "Wellington, Sandwich, Plimsoll, Pavlova. Connection: Named after famous people\n",
       "Custard, Vienna, Snowball, Cookie. Connection: TV cats\n",
       "Clover, Napoleon, Major, Boxer. Connection: Animal Farm characters</span>\n",
       "\n",
       "Groups:\n",
       "<span style='opacity: 1.0; display: inline; background-color: rgba(165, 165, 165, 0.1);' title='{{#each groups}}{{this}}. Connection:{{#unless @last}}\n",
       "{{/unless}}{{/each}}'><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Blanc, Brooks, B, Smith</span>. Connection:<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}}\n",
       "{{/unless}}'>\n",
       "</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Screwdriver, Hammer, Gimlet, Wrench</span>. Connection:<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}}\n",
       "{{/unless}}'>\n",
       "</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Sidecar, Manhattan, Gibson, Margarita</span>. Connection:<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}}\n",
       "{{/unless}}'>\n",
       "</span><span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this}}'>Puzzle, Business, Nuts, Suit</span>. Connection:<span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{#unless @last}}\n",
       "{{/unless}}'></span></span>\n",
       "\n",
       "Solved wall:</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;predicted_connections&#x27; temperature=0.0 max_tokens=144}}'>Groups:\n",
       "Blanc, Brooks, B, Smith. Connection: Comedic actors with the initials B\n",
       "Screwdriver, Hammer, Gimlet, Wrench. Connection: Tools\n",
       "Sidecar, Manhattan, Gibson, Margarita. Connection: Cocktails\n",
       "Puzzle, Business, Nuts, Suit. Connection: Types of magazines</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"9e2dbbcd-c9da-491d-bc01-4af2c312170a\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--dry-run flag passed. Exiting after one example.\n"
     ]
    }
   ],
   "source": [
    "# Remove dry-run when you are ready to run the full dataset\n",
    "predictions = run_openai(\n",
    "    dataset, task=\"task2\", split=\"validation\", num_in_context_examples=3, dry_run=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce our results from the paper, run the following\n",
    "\n",
    "> Note: this can take about ~2 hours per experiement. Results will be cached so re-running the same examples will not result in API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"gpt-3.5-turbo-0301\"\n",
    "model = \"gpt-4-0314\"\n",
    "model_dir = Path(f\"baselines/{model}\")\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "pred_dir = model_dir / \"predictions/task2\"\n",
    "pred_dir.parent.mkdir(exist_ok=True)\n",
    "results_dir = model_dir / \"results/task2\"\n",
    "results_dir.parent.mkdir(exist_ok=True)\n",
    "\n",
    "for num_in_context_examples in [10]:\n",
    "    predictions = run_openai(\n",
    "        dataset,\n",
    "        task=\"task2\",\n",
    "        model=model,\n",
    "        split=\"test\",\n",
    "        num_in_context_examples=num_in_context_examples,\n",
    "        silent=True,\n",
    "        stream=False,\n",
    "        caching=True,\n",
    "    )\n",
    "\n",
    "    pred_fp = pred_dir / f\"{num_in_context_examples}_in_context_examples.json\"\n",
    "    pred_fp.parent.mkdir(exist_ok=True)\n",
    "    pred_fp.write_text(json.dumps(predictions, ensure_ascii=False, indent=2))\n",
    "    evaluator = Evaluate(\n",
    "        str(pred_fp), dataset_path=\"./dataset/\", results_path=str(results_dir), split=\"test\"\n",
    "    )\n",
    "    evaluator.task2_connections_evaluation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results\n",
    "\n",
    "Re-generate plots from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install seaborn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# From: https://davidmathlogic.com/colorblind/#%23648FFF-%23785EF0-%23DC267F-%23FE6100-%23FFB000\n",
    "palette = [\"#648FFF\", \"#785EF0\", \"#DC267F\", \"#FE6100\", \"#FFB000\"]\n",
    "sns.set_theme(context=\"paper\", style=\"ticks\", palette=palette, font_scale=1.375)\n",
    "\n",
    "# Loop over all json files in the results directory using Pathlib\n",
    "df = {\"num_in_context_examples\": [], \"scores\": [], \"metric\": [], \"model\": []}\n",
    "\n",
    "for model in [\"gpt-4-0314\", \"gpt-3.5-turbo-0301\"]:\n",
    "    iterator = Path(f\"baselines/{model}/results/task2\").glob(\"*.json\")\n",
    "    iterator = sorted(iterator, key=lambda x: int(x.stem.split(\"_\")[0]))\n",
    "    for results_fp in iterator:\n",
    "        # Record the number of in-context examples\n",
    "        num_in_context_examples = int(results_fp.stem.split(\"_\")[0])\n",
    "        # 3 for the three metrics we report\n",
    "        df[\"num_in_context_examples\"].extend([f\"{num_in_context_examples}-shot\"] * 3)\n",
    "        results = json.loads(results_fp.read_text().strip())[\"global\"]\n",
    "        # Exact match\n",
    "        df[\"scores\"].append(results[\"exact_match\"])\n",
    "        df[\"metric\"].append(\"Exact match\")\n",
    "        # ROUGE-1 F1\n",
    "        df[\"scores\"].append(results[\"rouge1_f1\"])\n",
    "        df[\"metric\"].append(\"ROUGE-1 F1\")\n",
    "        # BERTScore F1\n",
    "        df[\"scores\"].append(max(results[\"bert_score_f1\"], 0))\n",
    "        df[\"metric\"].append(\"BERTScore F1\")\n",
    "        # Record model name\n",
    "        model_name = \"GPT-3.5-turbo\" if model == \"gpt-3.5-turbo-0301\" else \"GPT-4\"\n",
    "        df[\"model\"].extend([model_name] * 3)\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharey=\"row\", figsize=(9, 3.75))\n",
    "\n",
    "for i, model in enumerate([\"GPT-3.5-turbo\", \"GPT-4\"]):\n",
    "    g = sns.lineplot(\n",
    "        df[df[\"model\"] == model],\n",
    "        x=\"num_in_context_examples\",\n",
    "        y=\"scores\",\n",
    "        hue=\"metric\",\n",
    "        style=\"metric\",\n",
    "        markers=True,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=\"\", ylabel=\"\", title=model)\n",
    "\n",
    "\n",
    "# Set the x and y labels\n",
    "axes[0].set_xlabel(\"Number of in-context examples\")\n",
    "axes[0].set_ylabel(\"Score\")\n",
    "axes[0].legend_ = None\n",
    "# Move legend to top left of axes[0]\n",
    "axes[1].legend(loc=\"center right\")\n",
    "# Set x-axis tick labels to 45 degrees\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "    ax.yaxis.grid(True)\n",
    "\n",
    "# Additional global styling\n",
    "sns.despine(left=True)\n",
    "\n",
    "# Save a high-resolution version of the plot\n",
    "fig.tight_layout(w_pad=6)\n",
    "plt.savefig(\"baselines/task2_gpt_results.pdf\", dpi=500, facecolor=\"white\", bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "Compute several statistics that we reported in the paper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the fraction of groups with misformatted or hallucinated groups (task 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misformatted = 0\n",
    "hallucinated = 0\n",
    "# Choose the best performing model\n",
    "examples = json.loads(\n",
    "    Path(\"../baselines/gpt-4-0314/predictions/task1/3_in_context_examples.json\").read_text().strip()\n",
    ")\n",
    "for example in examples:\n",
    "    pred_words = [word for group in example[\"predicted_groups\"] for word in group]\n",
    "    gt_words = [word for group in example[\"gt_groups\"] for word in group]\n",
    "    misformatted += pred_words.count(\"\")\n",
    "    hallucinated += len([word for word in pred_words if word not in gt_words])\n",
    "# Thi is a proportion of # of groups with an error, as a single error gets counted as 1 wrong group\n",
    "print(f\"Misformatted: {misformatted}/{len(examples)*4} ({misformatted/(len(examples)*4):.2%})\")\n",
    "print(f\"Hallucinated: {hallucinated}/{len(examples)*4} ({hallucinated/(len(examples)*4):.2%})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the fraction of groups which contain the clues in (task 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_clues = 0\n",
    "# Choose the best performing model\n",
    "examples = json.loads(\n",
    "    Path(\"../baselines/gpt-4-0314/predictions/task2/10_in_context_examples.json\").read_text().strip()\n",
    ")\n",
    "for example in examples:\n",
    "    included_clues += sum(\n",
    "        bool(re.search(r\"\\(.*\\)$\", connection)) for connection in example[\"predicted_connections\"]\n",
    "    )\n",
    "print(\n",
    "    f\"Included clues: {included_clues}/{len(examples)*4} ({included_clues/(len(examples)*4):.2%})\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Human performance for task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human performance\n",
    "connections_solved = [\n",
    "    sum(item[\"connections\"]) for item in dataset[\"test\"][\"overall_human_performance\"]\n",
    "]\n",
    "solve_rate = sum(connections_solved) / (len(connections_solved) * 4)\n",
    "print(f\"Human performance on Task 2: {solve_rate:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "only-connect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
